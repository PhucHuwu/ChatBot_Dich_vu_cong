# Migration Guide - Chat History Optimization

## Tá»•ng quan

Version má»›i **tá»± Ä‘á»™ng tá»‘i Æ°u** viá»‡c sá»­ dá»¥ng chat_history, khÃ´ng cáº§n thay Ä‘á»•i code frontend/API.

## CÃ³ cáº§n thay Ä‘á»•i gÃ¬ khÃ´ng?

### âŒ KHÃ”NG Cáº¦N thay Ä‘á»•i

**Frontend/Client code** - Giá»¯ nguyÃªn nhÆ° cÅ©:

```javascript
// Váº«n gá»­i chat_history nhÆ° bÃ¬nh thÆ°á»ng
fetch('/api/chat', {
  method: 'POST',
  body: JSON.stringify({
    query: "CÃ²n cáº§n gÃ¬ ná»¯a?",
    chat_history: [...]  // â† Váº«n gá»­i
  })
})
```

**Backend API** - TÆ°Æ¡ng thÃ­ch ngÆ°á»£c hoÃ n toÃ n:

```python
# API signature khÃ´ng Ä‘á»•i
POST /api/chat
{
  "query": "string",
  "chat_history": [...]  # Optional, nhÆ° cÅ©
}
```

### âœ… Tá»± Ä‘á»™ng hoáº¡t Ä‘á»™ng

Há»‡ thá»‘ng **tá»± Ä‘á»™ng**:

1. Nháº­n `chat_history` tá»« request
2. PhÃ¢n tÃ­ch cÃ¢u há»i
3. Quyáº¿t Ä‘á»‹nh cÃ³ dÃ¹ng history khÃ´ng
4. Tráº£ vá» response nhÆ° cÅ©

## Äiá»ƒm khÃ¡c biá»‡t

### TrÆ°á»›c

```
Request â†’ Backend â†’ LLM (luÃ´n cÃ³ history)
```

### Sau

```
Request â†’ Backend â†’ Analyzer â†’ LLM (history khi cáº§n)
                      â†“
              Quyáº¿t Ä‘á»‹nh thÃ´ng minh
```

## Monitoring

### Log má»›i xuáº¥t hiá»‡n

**Standalone question**:

```
INFO: Context analysis: query='HÆ°á»›ng dáº«n...', history_count=5, use_history=False
INFO: Chat history skipped: standalone question detected
```

**Follow-up question**:

```
INFO: Context analysis: query='CÃ²n cáº§n...', history_count=3, use_history=True
INFO: Using chat history: 3 messages
```

### Metrics cáº§n theo dÃµi

1. **Tá»· lá»‡ sá»­ dá»¥ng history**

```bash
# Äáº¿m sá»‘ láº§n dÃ¹ng history
grep "Using chat history" logs/*.log | wc -l

# Äáº¿m sá»‘ láº§n skip
grep "Chat history skipped" logs/*.log | wc -l
```

Mong Ä‘á»£i: **20-40%** requests sá»­ dá»¥ng history

2. **Token tiáº¿t kiá»‡m**

-   TrÆ°á»›c: Avg 2500 tokens/request
-   Sau: Avg 800 tokens/request
-   Monitor qua dashboard LLM provider

3. **Latency**

-   Standalone queries nhanh hÆ¡n ~50%
-   Follow-up queries giá»¯ nguyÃªn

## Rollback (náº¿u cáº§n)

### Táº¯t tÃ­nh nÄƒng táº¡m thá»i

Sá»­a `rag.py`:

```python
def get_answer(query, chat_history=None, ...):
    # PhÃ¢n tÃ­ch tá»± Ä‘á»™ng
    # use_history = should_use_chat_history(query, chat_history)
    use_history = True  # â† Force luÃ´n dÃ¹ng history (nhÆ° cÅ©)

    # ...
```

### HoÃ n toÃ n revert

```bash
git revert <commit-hash>
```

## Testing sau deploy

### 1. Test standalone question

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "HÆ°á»›ng dáº«n Ä‘Äƒng kÃ½ tÃ i khoáº£n dá»‹ch vá»¥ cÃ´ng",
    "chat_history": []
  }'
```

**Kiá»ƒm tra log**: Pháº£i tháº¥y `use_history=False`

### 2. Test follow-up question

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "CÃ²n cáº§n gÃ¬ ná»¯a?",
    "chat_history": [
      {"role": "user", "content": "ÄÄƒng kÃ½ cáº§n CMND"}
    ]
  }'
```

**Kiá»ƒm tra log**: Pháº£i tháº¥y `use_history=True`

### 3. Test chá»§ Ä‘á» má»›i

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "HÆ°á»›ng dáº«n thanh toÃ¡n tiá»n Ä‘iá»‡n",
    "chat_history": [
      {"role": "user", "content": "ÄÄƒng kÃ½ tÃ i khoáº£n nhÆ° tháº¿ nÃ o?"}
    ]
  }'
```

**Kiá»ƒm tra log**: Pháº£i tháº¥y `use_history=False`

## Troubleshooting

### Váº¥n Ä‘á»: QuÃ¡ nhiá»u standalone Ä‘Æ°á»£c phÃ¡t hiá»‡n

**Triá»‡u chá»©ng**: > 80% queries khÃ´ng dÃ¹ng history

**NguyÃªn nhÃ¢n**: Patterns quÃ¡ strict

**Giáº£i phÃ¡p**:

1. Kiá»ƒm tra log DEBUG xem patterns nÃ o match
2. Äiá»u chá»‰nh ngÆ°á»¡ng trong `context_analyzer.py`
3. Giáº£m threshold topic continuity

### Váº¥n Ä‘á»: QuÃ¡ Ã­t standalone

**Triá»‡u chá»©ng**: > 80% queries váº«n dÃ¹ng history

**NguyÃªn nhÃ¢n**: Patterns khÃ´ng Ä‘á»§

**Giáº£i phÃ¡p**:

1. ThÃªm standalone keywords
2. TÄƒng ngÆ°á»¡ng Ä‘á»™ dÃ i cÃ¢u follow-up
3. Kiá»ƒm tra stopwords cÃ³ loáº¡i tá»« quan trá»ng khÃ´ng

### Váº¥n Ä‘á»: Performance khÃ´ng cáº£i thiá»‡n

**Triá»‡u chá»©ng**: Token/latency khÃ´ng giáº£m

**NguyÃªn nhÃ¢n**:

-   Cache Ä‘ang hoáº¡t Ä‘á»™ng â†’ Ä‘o sai
-   Háº§u háº¿t queries thá»±c sá»± cáº§n history

**Giáº£i phÃ¡p**:

1. Clear cache vÃ  Ä‘o láº¡i
2. PhÃ¢n tÃ­ch log xem tá»· lá»‡ use_history
3. A/B test vá»›i user thá»±c

## Performance Checklist

Sau deploy, kiá»ƒm tra:

-   [ ] Tá»· lá»‡ use_history trong khoáº£ng 20-40%
-   [ ] Avg tokens/request giáº£m 40-60%
-   [ ] Latency standalone queries giáº£m 40-50%
-   [ ] Answer quality khÃ´ng giáº£m (survey/feedback)
-   [ ] KhÃ´ng cÃ³ error spike
-   [ ] Cache stats bÃ¬nh thÆ°á»ng

## Support

Náº¿u gáº·p váº¥n Ä‘á»:

1. **Check logs** - TÃ¬m pattern láº¡
2. **Run tests** - `pytest tests/test_context_analyzer.py`
3. **Check metrics** - Token usage, latency
4. **Review code** - `context_analyzer.py`, `rag.py`, `llm_client.py`
5. **Read docs** - `docs/CONTEXT_ANALYZER.md`

## Káº¿t luáº­n

âœ… **Zero-downtime migration** - KhÃ´ng cáº§n thay Ä‘á»•i client  
âœ… **Backward compatible** - API giá»¯ nguyÃªn  
âœ… **Auto-optimize** - Tá»± Ä‘á»™ng tá»‘i Æ°u  
âœ… **Monitorable** - Äáº§y Ä‘á»§ logs & metrics  
âœ… **Rollback-able** - Dá»… dÃ ng revert náº¿u cáº§n

Happy deploying! ğŸš€
